{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(\"how can langsmith help with testing?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_course_outline(overall_topic):\n",
    "    # prompt = ChatPromptTemplate.from_messages([\n",
    "    #     (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    #     (\"user\", \"{input}\")\n",
    "    # ])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Create a detailed course outline for teaching '{overall_topic}' to a total beginner,\n",
    "    progressing from basic concepts to advanced {overall_topic} techniques.\n",
    "    The outline should be structured in JSON format, with explicit headers for topics and sub-topics,\n",
    "    each including detailed content pointers for learning objectives.\n",
    "    Organize the outline to facilitate easy understanding and navigation through the course material.\n",
    "\n",
    "    JSON Structure:\n",
    "    {{\"\n",
    "    \"name\": \"{overall_topic}\",\n",
    "    \"topics\": [\n",
    "        {{\n",
    "        \"topic\": \"Introduction to SQL\",\n",
    "        \"sub-topics\": [\n",
    "            {{\n",
    "            \"sub-topic\": \"What is SQL?\",\n",
    "            \"content pointers\": [\n",
    "                \"Definition and purpose of SQL\",\n",
    "                \"History and evolution of SQL\",\n",
    "                \"SQL vs. NoSQL databases\"\n",
    "            ]\n",
    "            }},\n",
    "            {{\n",
    "            ...additional sub-topics...\n",
    "            }}\n",
    "        ]\n",
    "        }},\n",
    "        {{\n",
    "        ...additional topics...\n",
    "        }}\n",
    "    ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt, max_tokens=1024, temperature=0.5, stop=None)\n",
    "    json_response = response.content\n",
    "    json_response = json_response.strip('```json').strip('```')\n",
    "\n",
    "\n",
    "    # Define the filename based on the overall_topic\n",
    "    filename = f\"{overall_topic}.json\"\n",
    "\n",
    "    # Write the JSON string to a file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(json_response)\n",
    "\n",
    "    print(f\"Course outline saved as {filename}\")\n",
    "\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(sub_topic, next_sub_topic, content_pointers):\n",
    "    prompt = f\"Generate the content for the bullet point '{sub_topic}' without delving into '{next_sub_topic}'. Focus on the following content pointers:\\n\"\n",
    "    for pointer in content_pointers:\n",
    "        prompt += f\"- {pointer}\\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_with_openai(prompt):\n",
    "    # Adjust parameters as necessary for your use case\n",
    "    response = llm.invoke(prompt, max_tokens=1024, temperature=0.5, stop=None)\n",
    "    content_text = response.content if hasattr(response, 'content') else \"Content not found\"\n",
    "    return content_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article(course_outline):\n",
    "    course_output = {\"name\": course_outline[\"name\"], \"topics\": []}  # Initialize with course name and empty topics list\n",
    "    total_sub_topics = sum(len(topic[\"sub-topics\"]) for topic in course_outline[\"topics\"])\n",
    "    completed_sub_topics = 0\n",
    "\n",
    "    for topic in course_outline[\"topics\"]:\n",
    "        topic_name = topic[\"topic\"]\n",
    "        new_topic = {\"topic\": topic_name, \"sub-topics\": []}  # Initialize a new topic dictionary\n",
    "\n",
    "        for i, sub_topic in enumerate(topic[\"sub-topics\"]):\n",
    "            sub_topic_name = sub_topic[\"sub-topic\"]\n",
    "            content_pointers = sub_topic[\"content pointers\"]\n",
    "            next_sub_topic = topic[\"sub-topics\"][i + 1][\"sub-topic\"] if i + 1 < len(topic[\"sub-topics\"]) else \"the next topic\"\n",
    "\n",
    "            # Generate prompt for each sub-topic\n",
    "            prompt = generate_prompt(sub_topic_name, next_sub_topic, content_pointers)\n",
    "\n",
    "            # Generate content based on prompt\n",
    "            article_content = generate_content_with_openai(prompt)\n",
    "\n",
    "            # Append generated content to the sub-topic\n",
    "            new_sub_topic = {\"sub-topic\": sub_topic_name, \"content\": article_content}\n",
    "            new_topic[\"sub-topics\"].append(new_sub_topic)\n",
    "\n",
    "            # Update progress\n",
    "            completed_sub_topics += 1\n",
    "            progress_percentage = (completed_sub_topics / total_sub_topics) * 100\n",
    "            print(f\"Completed: {completed_sub_topics}/{total_sub_topics} sub-topics. Progress: {progress_percentage:.2f}%\")\n",
    "\n",
    "        course_output[\"topics\"].append(new_topic)\n",
    "\n",
    "    return course_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read json file and print out content\n",
    "import json\n",
    "\n",
    "def read_json_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file '{filename}'.\")\n",
    "\n",
    "def print_json_contents(data):\n",
    "    if data:\n",
    "        print(json.dumps(data, indent=2))\n",
    "    else:\n",
    "        print(\"No data to print.\")\n",
    "\n",
    "def main():\n",
    "    filename = \"SQL.json\"  # Change this to the path of your JSON file\n",
    "    course_outline = read_json_file(filename)\n",
    "    print_json_contents(course_outline)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 1/17 sub-topics. Progress: 5.88%\n",
      "Completed: 2/17 sub-topics. Progress: 11.76%\n",
      "Completed: 3/17 sub-topics. Progress: 17.65%\n",
      "Completed: 4/17 sub-topics. Progress: 23.53%\n",
      "Completed: 5/17 sub-topics. Progress: 29.41%\n",
      "Completed: 6/17 sub-topics. Progress: 35.29%\n",
      "Completed: 7/17 sub-topics. Progress: 41.18%\n",
      "Completed: 8/17 sub-topics. Progress: 47.06%\n",
      "Completed: 9/17 sub-topics. Progress: 52.94%\n",
      "Completed: 10/17 sub-topics. Progress: 58.82%\n",
      "Completed: 11/17 sub-topics. Progress: 64.71%\n",
      "Completed: 12/17 sub-topics. Progress: 70.59%\n",
      "Completed: 13/17 sub-topics. Progress: 76.47%\n",
      "Completed: 14/17 sub-topics. Progress: 82.35%\n",
      "Completed: 15/17 sub-topics. Progress: 88.24%\n",
      "Completed: 16/17 sub-topics. Progress: 94.12%\n",
      "Completed: 17/17 sub-topics. Progress: 100.00%\n",
      "Article saved as SQL.json\n"
     ]
    }
   ],
   "source": [
    "# Generate the article\n",
    "num_articles = 10 # process number of articles at a time - allow article to be generated more coherently\n",
    "topic = \"SQL\"\n",
    "filename = f\"{topic}_output.json\"\n",
    "\n",
    "# course_outline = generate_course_outline(topic)\n",
    "# print(course_outline)\n",
    "\n",
    "course_outline_dict = json.loads(course_outline)\n",
    "article = generate_article(course_outline_dict)\n",
    "\n",
    "with open(filename, \"w\") as file:\n",
    "    json.dump(article, file)\n",
    "\n",
    "print(f\"Article saved as {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roadmap_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
